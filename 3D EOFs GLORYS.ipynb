{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "268cacf7",
   "metadata": {},
   "source": [
    "# Compute GLORYs EOFs\n",
    "## Created by Dani Lafarga 5/28/2025\n",
    "## Last updated on: 8/14/2025\n",
    "This program will compute 3D EOFs from GLORYS temperature data found at:  https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/description\n",
    "\n",
    "The program will partition the data according to the total amount of GB specified by the user to compute both covariance and 3D EOFs. \n",
    "\n",
    "Program will output to a specified directory called EOF_directory:\n",
    "- eigenvalues/eigenvectors in a CSV file\n",
    "- EOFs in seperate NetCDF files according to mode\n",
    "\n",
    "This version assumes the user will be able to load one year's worth of anomaly data. \n",
    "\n",
    "Code is split up into 4 sections:\n",
    "- Section 1: Defining all directories and dimension variables\n",
    "- Section 2: Compute Covariance using PIM\n",
    "- Section 3: Compute eigenvalues/eigenvectors\n",
    "- Section 4: Compute EOFs in parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b62a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import meshgrid\n",
    "import scipy.io as sc\n",
    "import os\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linspace\n",
    "from numpy import meshgrid\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib\n",
    "import math\n",
    "import time\n",
    "\n",
    "import netCDF4 as nc \n",
    "from netCDF4 import Dataset as ds\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "\n",
    "# Function creates a folder if it doesnt already exist\n",
    "# Input:\n",
    "#         - folder_path: string with the path name to folder\n",
    "def create_folder(folder_path):\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Folder '{folder_path}' created.\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' already exists.\")\n",
    "     \n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function converts longitude from 0 to 360 to centered at 180. This is just for naming purposes.\n",
    "# it does not shift the axis of the data\n",
    "# Input:\n",
    "#         - lon_0_360: float with the longitude value from 0 to 360\n",
    "# Output:\n",
    "#         - convert: String with the longitude value on a 180 centered scale\n",
    "\n",
    "# Important Variables:\n",
    "#         - lon_180_w_180_e: float with the longitude value on a 180 centered scale\n",
    "def convert_longitude(lon_0_360):\n",
    "    lon_180_w_180_e = lon_0_360 - 360 if lon_0_360 > 180 else lon_0_360\n",
    "    if lon_180_w_180_e < 0:\n",
    "        lon_180_w_180_e = abs(lon_180_w_180_e)\n",
    "        convert = f\"{lon_180_w_180_e}$^\\circ$W\"\n",
    "    else:\n",
    "        convert = f\"{lon_180_w_180_e}$^\\circ$E\"\n",
    "    return convert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1bb824-5040-47b9-9c45-da343d0b8c96",
   "metadata": {},
   "source": [
    "# Section 1: Defining ALL directories and dimension variables\n",
    "## Dimension variabels:\n",
    "- lat: latitude from raw data\n",
    "- lon: longitude from raw data\n",
    "- depths: depth from raw data\n",
    "- years: defined years\n",
    "- cut_lat: cut lattitude values based on lat_start and lat_end\n",
    "- cut_lon: cut longitude values based on lon_start and lon_end\n",
    "- cut_depths: cut depth values based on depth_end\n",
    "\n",
    "## Directories that must be changed by user:\n",
    "- data_directory: This will be the folder you will be reading the raw data from. This is used mainly to define the latitude, longitude, and depths if they arent already saved in the anomalies\n",
    "- anomalies_directory: This is the folder that contains all anomalies. **Code will need already computed anomalies** if you haven't already done so please compute them using the compute anomalies and climatologies code.\n",
    "- EOF_directory: this will be where we save all EOFs and eigenvalues/eigenvectors. This folder will be created for you in the first section\n",
    "  \n",
    "## Variables that need to be changed by user\n",
    "- years: please set this to the starts and end year of the anomalies\n",
    "- lat_start: Starting latitude index. If entire region use 0\n",
    "- lat_end: End latitude index. If entire region use len(lat)\n",
    "- lon_start: Starting longitude index. If entire region use 0\n",
    "- lon_end: End longitude index. If entire region use len(lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ccfbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'E:/GLORYS/cut_EOFs/Entire Ocean PIM' already exists.\n"
     ]
    }
   ],
   "source": [
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function get_var() will get common variables that will be required for climatologies,\n",
    "# anomalies, and EOFs\n",
    "# Input: \n",
    "#         - MON_INDEX: month index tells us home many years we will have \n",
    "#              Months 1-6 have 29 years\n",
    "#              Months 7-12 only have 28 years\n",
    "#              MON_INDEX = 0 means 3 month season\n",
    "# Output: \n",
    "#         - lat: 1d array with all latitude values\n",
    "#         - lon: 1d array with all longitude values\n",
    "#         - depth: 1d array with all depth values\n",
    "#         - years: 1d array with all year values\n",
    "def get_var():\n",
    "    fn     = 'thetao.mon.mean.1993.nc'\n",
    "    fn     = os.path.join(data_directory, fn)\n",
    "    fn     =  ds(fn,'r')\n",
    "    lat    = fn.variables['latitude'][:].data    # read in latitude\n",
    "    lon    = fn.variables['longitude'][:].data   # read in longitude\n",
    "    depths = fn.variables['depth'][:].data       # read in depth\n",
    "    fn.close()\n",
    "    return lat, lon, depths\n",
    "\n",
    "# Please change the following directories\n",
    "data_directory          = 'E:/GLORYS/'\n",
    "anomalies_directory     = os.path.join(data_directory, 'Anomalies/Winter Avg' )\n",
    "EOF_directory           = os.path.join(data_directory, 'cut_EOFs/Entire Ocean PIM')\n",
    "\n",
    "create_folder(EOF_directory) # if directory doesnt exist create it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e5fb0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon, depths = get_var() # get latitude, longitude, and latitude variables\n",
    "\n",
    "\n",
    "'''\n",
    "If you would like to do a regional calculation consider the following indices\n",
    "\n",
    "depth_end = 32 # first 500 m\n",
    "\n",
    "# for the entire Pacific\n",
    "lat_start = 720\n",
    "lat_end   = 1801\n",
    "lon_start = 1440\n",
    "lon_end   = 3600\n",
    "depth_end = 32\n",
    "\n",
    "\n",
    "# for ENSO\n",
    "lat_start = 600\n",
    "lat_end   = 1321\n",
    "lon_start = 1320\n",
    "lon_end   = 3481\n",
    "depth_end = 32\n",
    "\n",
    "\n",
    "# Global\n",
    "lat_start = 0\n",
    "lat_end   = len(lat)\n",
    "lon_start = 0\n",
    "lon_end   = len(lon)\n",
    "depth_end = len(depths)\n",
    "'''\n",
    "\n",
    "\n",
    "lat_start = 0\n",
    "lat_end   = len(lat)\n",
    "lon_start = 0\n",
    "lon_end   = len(lon)\n",
    "depth_end = len(depths)\n",
    "\n",
    "years  = np.linspace(1994, 2021,28, dtype=\"int\")\n",
    "\n",
    "cut_lat = lat[lat_start:lat_end]\n",
    "cut_lon = lon[lon_start:lon_end]\n",
    "cut_depths = depths[:depth_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a572273",
   "metadata": {},
   "source": [
    "# Section 2: Compute Covariance\n",
    "**Please be sure file names line up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83289b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function reads in cut anomalies, will take out NaNs, and then flattten to a 1D array\n",
    "# \n",
    "# Input:\n",
    "#         - year: int with the year to read in\n",
    "# Output:\n",
    "#         - anom: 1d array that contains anomalies of the file without any NaN\n",
    "def read_anom_compressed(year):\n",
    "    fn   = 'anom.mon.'+str(year)+'.nc'                 # change file name\n",
    "    fn   = os.path.join(anomalies_directory, fn)       # join with the directory that can be changed\n",
    "    nc0  = ds(fn, 'r')\n",
    "    anom = nc0.variables['anom'][:depth_end, lat_start:lat_end, lon_start:lon_end]\n",
    "    if anom.shape[2] == len(lon):                  # for full ocean there is a mismatch in GLORYS\n",
    "        anom.mask[13, 969, 3717] = True\n",
    "    anom = anom.compressed()                           # flatttentens and gets rid of NaN\n",
    "    nc0.close()\n",
    "    return anom\n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function reads in cut anomalies for multiple years, and will put them all into a matrix\n",
    "# \n",
    "# Input:\n",
    "#         - year_array: 1D array with mutliple years. Range will be from original year array \n",
    "# Output:\n",
    "#         - anom_mat: 2D array where rows are data points, and columns are the years defined by\n",
    "#                     the year array.  Array does not contain Nan (land points)\n",
    "def read_anom_compressed_matrix(year_array):\n",
    "    anom_mat = []                         # initialize array matrix as a list\n",
    "    for year in year_array:               # read in anom for every year\n",
    "        anom = read_anom_compressed(year) # read in anomaly with no NaN\n",
    "        anom_mat.append(anom)             # add to the array matrix \n",
    "    anom_mat = np.array(anom_mat)         # turn anom into an array\n",
    "    return anom_mat\n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# function will compute how many years could be read in at a time for matrix multiplication\n",
    "# input: \n",
    "#       - GB_avail: int taken as input from user\n",
    "\n",
    "# output:\n",
    "#       - years_possible: int that will define how many years can be read in each year for\n",
    "#                         the matrix multiplication in the covariance calculation\n",
    "# important variables:\n",
    "#       - anom: a compressed 1D array with anomalies and no NaN\n",
    "def years_possible_for_cov(GB_avail):\n",
    "    anom = read_anom_compressed(1994) # reading in one year of data with no NaN\n",
    "    if GB_avail*1e9 < 2*anom.nbytes:  # checking if one year is possible for the calculation\n",
    "        years_possible = 1\n",
    "        print(f\"Data exceeds the inputed memory try reading in one year at a time.\")\n",
    "        print(f\"One year will require a total of {anom.nbytes*2} bytes. If this is too much try a smaller region.\")\n",
    "        return years_possible\n",
    "    length_test = (GB_avail*1e9)/(anom.nbytes)    # divide the GB by bytes to convert to enteries\n",
    "    years_possible = 1                            # initialize total years possible\n",
    "    while 1:                                      # finding greatest integer divisor\n",
    "        if length_test/(2*years_possible) > 1:\n",
    "            years_possible = years_possible + 1\n",
    "            continue;\n",
    "        else:\n",
    "            years_possible = years_possible-1\n",
    "            break;\n",
    "    if years_possible > len(years):              # shouldn't be more than the total amount of years\n",
    "        years_possible = len(years)\n",
    "    print(f\"With {GB_avail} GB you will be able to read in {years_possible} years at a time\")\n",
    "    total_GB = (years_possible * 2) * anom.nbytes\n",
    "    total_GB = total_GB / 1e9\n",
    "    print(f\"{years_possible} years will require {total_GB} GB\")\n",
    "    return np.int(years_possible)\n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# function will calculate how many GB memory it will take to calculate the covariance matrix\n",
    "# a specified amount of years \n",
    "# input:\n",
    "#     - year: int with however many years\n",
    "# output: will print total GB required\n",
    "def year_GB_calc(year):\n",
    "    if year > len(years): # should not excede the total amount of years we have\n",
    "        print(f\"That's more years than we have. Did you mean {len(years)}? Try again with that many.\")\n",
    "        return\n",
    "    # calculating the total GB\n",
    "    anom = read_anom_compressed(1994)\n",
    "    total_GB = (year * 2) * anom.nbytes\n",
    "    total_GB = total_GB / 1e9\n",
    "    print(f\"{year} years will take {total_GB} GB\")   \n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function computes the covariance matrix in time for the data. \n",
    "# Covariance is computed by doing the dot product of one anomally array at time t\n",
    "# with all other anomalies at time t'. \n",
    "# to avoid redundancies the code will explot the symmetry of the covariance matrix\n",
    "'''\n",
    "Example\n",
    "   Anomaly Mult: \n",
    "            let t = 2\n",
    "                   o t' = t+1\n",
    "                                        anom(t) * anom(t+1) = a\n",
    "                                        -> cov(2,3) = cov(3,2) = a\n",
    "                   o t' = t+2\n",
    "                                        anom(t) * anom(t+2) = b\n",
    "                                        -> cov(2,4) = cov(4,2) = b\n",
    "                   o t' = t+3\n",
    "                                        anom(t) * anom(t+3) = c\n",
    "                                        -> cov(2,5) = cov(5,2) = c\n",
    "                                                ┌               ┐\n",
    "                                        cov =   │  # # # # # #  │\n",
    "                                                │  # # # # # #  │\n",
    "                                                │  # # t a b c  │\n",
    "                                                │  # # a # # #  │\n",
    "                                                │  # # b # # #  │\n",
    "                                                │  # # c # # #  │\n",
    "                                                └               ┘\n",
    "For multiple years at once a , b, and c are 1D arrrays input into the covariance matrix\n",
    "'''\n",
    "\n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function computes the covariance matrix in time for the data. \n",
    "# Covariance is computed by doing the dot product of one anomally array at time t\n",
    "# with all other anomalies at time t'. \n",
    "# to avoid redundancies the code will explot the symmetry of the covariance matrix\n",
    "# this function is derivative of the previous cov() function\n",
    "# Input:\n",
    "#         - years: 1D array of ints with all years to be used in computation. These are all \n",
    "#                  the anomalies which will be read in \n",
    "#         - years_possible: the total amount of years to read in per iteration based on the specific amount of memory\n",
    "#                  the user wants to use. \n",
    "# Output:\n",
    "#         - covariance_mat: 2D covariance matrix(floats)\n",
    "# Important Variables:   \n",
    "#         - Y: total amount of years. This will give us the dimensions for our square covariance matrix (Y by Y)\n",
    "#         - t: the time index(int). this will tell us what diagonal we are on so we can exploit symmetry.\n",
    "#              It will advance by years_possible (ex. years_possible = 3, t = 0,3,6...)\n",
    "#         - anom: a 2D N' by years_possible matrix that contain anomalies starting at time years[t]. \n",
    "#         - t_prime: all values from t+1 to the last time step index(int). This will advance by years_possible just\n",
    "#                  like t\n",
    "#         - year_array: the year aray value starting at t\n",
    "#         - year_array_prime: the year aray value starting at t_prime\n",
    "'''\n",
    "             example: years = [1993 to 2021], if t = 3 and years_possible = 3\n",
    "                     \n",
    "                     year_array = [1995, 1996, 1997]\n",
    "                     so...\n",
    "                     t_prime = 3 to 29 nd increases by 3\n",
    "                     \n",
    "                     at t_prime = 3\n",
    "                        -> year_array_prime = [1995, 1996, 1997]\n",
    "                        \n",
    "                     at t_prime = 6\n",
    "                        -> year_array_prime = [1998, 1999, 2000]\n",
    "                        \n",
    "'''\n",
    "#         - anom_tprime: a 2D N' by years_possible matrix that contain anomalies starting at time years[t]. \n",
    "#         - resulting_matrix_mult: result of anom dotted with anom_tprime. This makes it easier to input into covariance matrix\n",
    "#                                 the result will be a years_possible by years_possible matrix\n",
    "def cov_mat(years, years_possible):\n",
    "    start = time.time()\n",
    "    Y = len(years)\n",
    "    covariance_mat = np.zeros((Y,Y))\n",
    "    for t in range(0,Y,years_possible):\n",
    "        year_array = years[t:t+years_possible]           # read in the array of years\n",
    "        anom = read_anom_compressed_matrix(year_array)   # read in anomalies for years specified \n",
    "        for t_prime in range(t,Y,years_possible):      \n",
    "            year_array_prime = years[t_prime:t_prime+years_possible]   # read in the array of years\n",
    "            anom_tprime = read_anom_compressed_matrix(year_array_prime)# read in anomalies for years specified \n",
    "            resulting_matrix_mult =  np.dot(anom, anom_tprime.T)       # do dot product for covariance\n",
    "            covariance_mat[t:t+years_possible, t_prime: t_prime+len(year_array_prime)] = resulting_matrix_mult   # input to covariance matrix\n",
    "            covariance_mat[t_prime: t_prime+len(year_array_prime),t:t+years_possible]  = resulting_matrix_mult.T # input the reflected side\n",
    "    end = time.time()\n",
    "    time_total = end-start\n",
    "    print(time_total)\n",
    "    return covariance_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6649b25-91b6-4896-b14a-fd0f6e707385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How Many GB would you like to use?: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 5 GB you will be able to read in 2 years at a time\n",
      "2 years will require 4.118381888 GB\n"
     ]
    }
   ],
   "source": [
    "# calculating years possible according to specified memory\n",
    "GB_avail = int(input(\"How Many GB would you like to use?:\"))\n",
    "years_possible = years_possible_for_cov( GB_avail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b47d5f08-97b0-41e5-92f7-471cfeda3988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How many years would you like to read?: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 years will take 6.177572832 GB\n"
     ]
    }
   ],
   "source": [
    "# how many GB for the amount of years\n",
    "years_possible = int(input(\"How many years would you like to read?:\"))\n",
    "year_GB_calc(years_possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c431a24-899c-4e0d-b1b6-4fbbcc4f4e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2049.655123233795\n"
     ]
    }
   ],
   "source": [
    "cov = cov_mat(years, years_possible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d13be15-41cb-41c3-933c-c2b62622002d",
   "metadata": {},
   "source": [
    "# Section 3: Compute eigenvalues/eigenvectors\n",
    "compute eigenvectors and eigenvalues from the temporal covariance matrix.\n",
    "$$\n",
    " C_T v_k = \\lambda_k v_k\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $C_S$ : temporal covariance\n",
    "- $v_k$ : eigenvectors. These are also pricipal components (PC)\n",
    "- $\\lambda_K$ : eigenvalues. These also give associated variability\n",
    "- $k$ : the mode.The total amount of these will depend on the dimensions of the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "47612a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function computes eigenvectors and values of the covariance matrix and sort them by variance greatest to least\n",
    "# function will also check to make sure they are normalized and orthogonal\n",
    "# Input:\n",
    "#         - cov: 2D covariance matrix. Cannot have any NaNs!\n",
    "# Output:\n",
    "#         - eigvals: 1D array with all eigenvalues of covariance matrix sorted (float)\n",
    "#         - eigvecs: 2D matrix with corresponding sorted eigenvectors of covariance matrix (float)\n",
    "# Important Variables: \n",
    "def find_eigen(cov):\n",
    "    eigvals, eigvecs = np.linalg.eig(cov)\n",
    "    eigvecs = np.array(eigvecs)\n",
    "    \n",
    "    # Check to make sure vectors are orthogonal\n",
    "    n, m = eigvecs.shape\n",
    "    for col_i in range(m):\n",
    "        for col_j in range(m):\n",
    "            if col_i < col_j:  # use strictly less than because we don't want to consider a column with itself, and the dot product is commutable so order doesn't matter\n",
    "                is_orthogonal = np.dot(eigvecs[:, col_i], eigvecs[:, col_j])\n",
    "                if not np.isclose(is_orthogonal, 0):\n",
    "                    raise ValueError(f\"Eigenvector {col_i} and Eigenvector {col_j} are not orthogonal.\")\n",
    "    # checking magnitude of evals\n",
    "    for col_i in range(m):\n",
    "        is_one = np.linalg.norm(eigvecs[:,col_i])\n",
    "        if not np.isclose(is_one, 1):\n",
    "            raise ValueError(f\"Eigenvector {col_i} is not one\")\n",
    "            \n",
    "    # sort eigenvalues and eigenvectors\n",
    "    eig_index = np.argsort(eigvals)\n",
    "    eig_index = np.flip(eig_index)\n",
    "    \n",
    "    new_eigvals = eigvals[eig_index[:]]\n",
    "    eigvals = new_eigvals\n",
    "    \n",
    "    new_eigvecs = eigvecs[:,eig_index]\n",
    "    eigvecs = new_eigvecs \n",
    "    return eigvals,eigvecs\n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function saves eigenvalues and eigencvectors into a csv file \n",
    "# \n",
    "# Input:\n",
    "#         - eigvals: 1D array with eigenvalues\n",
    "#         - eigvecs: 2D matrix with eigenvectors\n",
    "#         - month: string with the month the eigenvec/eigenvals belong to\n",
    "# Output:\n",
    "#         - None: function saves to a file \n",
    "def save_evals(eigvals,eigvecs,month):\n",
    "    # Prepare data for saving\n",
    "    # Create a 2D array with eigenvalues and eigenvectors\n",
    "    data = np.hstack((eigvals.reshape(-1, 1), eigvecs.T))\n",
    "    \n",
    "    # Save to CSV file\n",
    "    create_folder(EOF_directory)\n",
    "    fn     = month+'_eigenvalues_eigenvectors.csv'\n",
    "    fn     = os.path.join(EOF_directory, fn)\n",
    "    with open(fn, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write the header\n",
    "        header = ['Eigenvalue'] + [f'Eigenvector {i+1}' for i in range(eigvecs.shape[1])]\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        # Write the data\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    print(\"Eigenvalues and eigenvectors saved to 'eigenvalues_eigenvectors.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "id": "2d67a3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'E:/GLORYS/cut_EOFs/Entire Ocean PIM' already exists.\n",
      "Eigenvalues and eigenvectors saved to 'eigenvalues_eigenvectors.csv'\n"
     ]
    }
   ],
   "source": [
    "eigvals,eigvecs = find_eigen(cov)\n",
    "save_evals(eigvals,eigvecs,'Winter Avg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09b48260",
   "metadata": {},
   "source": [
    "# Section 4: Compute EOFs in parts\n",
    "\n",
    "### Space time anomaly Matrix:\n",
    "Let an eigenvector be defined as $\\vec{v_k}$ where $k$ is the eigenvector number or mode number. There are a total of Y modes that are used. Each EOF $u_k$ can be computed by the projection of anomalies $A$ onto $v_k$ in the following way:\n",
    "$$\n",
    "\\begin{equation}\n",
    "    u_k = \\frac{Av_k}{|Av_k|},\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $|Av_k|$ is the Euclidean norm of the vector $Av_k$.\n",
    "\n",
    "This algorithm breaks up this computation so that it reads anomalies a chunk at a time and writes to EOF files a chunk at a time. Algorithm will skip over any row that is NaN which is consistent for every year. Meaning it will neither read nor write to those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0acfa434-7d45-4d1a-8a07-835456cb25d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function will read in eigenvalues and eigenvectors saved in CSV file based on the EOF_directory\n",
    "# Input: None\n",
    "# Output:\n",
    "#         - eigvals: a 1D float array with all eigenvectors corresponding eigenvalues\n",
    "#         - eigvecs: a 2D float array with all eigenvectors in the columns of the matrix\n",
    "\n",
    "# Important Variables:\n",
    "#         - month: defined previously by the Set_Global_Variables function \n",
    "#         - EOf_directory: defined by the set_EOF_Anom_directory function \n",
    "def read_evec(prefix):\n",
    "    # Read the CSV file\n",
    "    fn     = prefix +'_eigenvalues_eigenvectors.csv'\n",
    "    fn     = os.path.join(EOF_directory, fn)\n",
    "    df = pd.read_csv(fn)\n",
    "\n",
    "    # Extract the eigenvalues\n",
    "    eigvals = df['Eigenvalue'].values\n",
    "\n",
    "    # Extract the eigenvectors\n",
    "    eigvecs = df.drop(columns=['Eigenvalue']).values.T\n",
    "    return eigvals,eigvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4ac579a1-02dd-4c5e-8f44-d0cdf14e27db",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,eigvecs = read_evec('Winter Avg')\n",
    "eigvecs = eigvecs.astype(np.float32) # making sure eigenvectors are of the same type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "29f529ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function checks if a file exists and if it does, continues to the next iteration.\n",
    "# Input:\n",
    "#         - file_path: string with the path name to folder\n",
    "# Outputs:\n",
    "#         - True if file doesnt exists\n",
    "#         - False if file exists\n",
    "# Important Variables:\n",
    "def check_file_and_continue(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File '{file_path}' exists. Moving to next iteration.\")\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function reads in raw cut anomalies\n",
    "#\n",
    "# Input:\n",
    "#         - year: int with the specific year to read\n",
    "# Output:\n",
    "#         - anom: 3D array of dim (depth, lat, lon) with the anomaly data\n",
    "def read_anom_raw(year):\n",
    "    fn   = 'anom.mon.'+str(year)+'.nc'            # change file name\n",
    "    fn   = os.path.join(anomalies_directory, fn)  # join with the directory that can be changed\n",
    "    nc0 = ds(fn, 'r')\n",
    "    anom = nc0.variables['anom'][:depth_end, lat_start:lat_end, lon_start:lon_end]\n",
    "    if anom.shape[2] == len(lon):                 # for full ocean there is a mismatch\n",
    "        anom.mask[13, 969, 3717] = True\n",
    "    anom = anom.filled()\n",
    "    nc0.close()\n",
    "    return anom\n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function reads anomaly data but only outputs matrix with no NaNs\n",
    "# depth is specified to save RAM while reading. Without the specified depth you would be reading in all depths\n",
    "# Input:\n",
    "#         - year: int with the specific year to read\n",
    "#         - read: 2D array with indexes of what page (depth), row, and column has data.\n",
    "#                 read[:,0]- the page (depth) with data\n",
    "#                 read[:,1]- the rows with data\n",
    "#                 read[:,1]- the columns with data\n",
    "# Output:\n",
    "#         - anom: 2D matrix at specified year and depth with no NaNs\n",
    "\n",
    "def read_anom_parts(year,read):\n",
    "    anom = read_anom_raw(year)\n",
    "    anom = anom[read[:,0], read[:,1], read[:,2]]\n",
    "    return anom\n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function Created the files which will be aggregated a chunk at a time.\n",
    "# The files must be created  first so we can more easily access and aggregate them.\n",
    "# Input:\n",
    "#         - month: string  where to save the EOFs\n",
    "#         - total_modes: int with the total amount of modes I want.\n",
    "#                        Maximum is the total amount of time steps\n",
    "# Output:\n",
    "#         - None: the function will create files for all EOF modes\n",
    "# Important Variables:\n",
    "def create_EOF_files(total_modes):\n",
    "    create_folder(EOF_directory)                  # create folder named by the month\n",
    "    anom_base = read_anom_raw(1998)               # read in one anomaly to base the dimensions of EOF\n",
    "    EOF_mat = np.full_like(anom_base, np.nan)     # create a matrix with the same dim size as the anomalies\n",
    "    for mode in range(1,total_modes+1):           # for all the modes\n",
    "        # Create a new NetCDF file\n",
    "        fn = 'EOF_'+str(mode)+'.nc'               # file name for EOFs\n",
    "        fn     = os.path.join(EOF_directory, fn)  # join with EOF path\n",
    "        if not check_file_and_continue(fn):                      # if the file does already exist continue\n",
    "            continue;\n",
    "        ncfile = ds(fn, 'w', format='NETCDF4')                   # if the file doesnt exist create it\n",
    "        \n",
    "        # Define dimensions\n",
    "        ncfile.createDimension('depth', EOF_mat.shape[0])\n",
    "        ncfile.createDimension('lat', EOF_mat.shape[1])\n",
    "        ncfile.createDimension('lon', EOF_mat.shape[2])\n",
    "\n",
    "        # Create a variable for EOFs\n",
    "        lat_save = ncfile.createVariable('latitude', 'float32', ('lat'), fill_value = np.nan)\n",
    "        lon_save = ncfile.createVariable('longitude', 'float32', ('lon'), fill_value = np.nan)\n",
    "        depth_save   = ncfile.createVariable('depth', 'float32', ('depth'), fill_value = np.nan)\n",
    "        var = ncfile.createVariable('EOF', 'f4', ('depth', 'lat', 'lon'), fill_value = np.nan)\n",
    "        \n",
    "        # saving variables\n",
    "        lat_save[:]  = cut_lat\n",
    "        lon_save[:]  = cut_lon\n",
    "        depth_save[:]    = cut_depths\n",
    "        \n",
    "        var[:] = EOF_mat # save the empty EOF\n",
    "        ncfile.close()   # close the file\n",
    "    print(f\"Total of '{mode}' EOF files created or ready to save to.\")\n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# function will return the total amount of enteries that can be read in for every year\n",
    "# given the total GB availiable\n",
    "# input:\n",
    "#     - GB_avil: int that decribes the total GB that is avaliable to use\n",
    "# ouput:\n",
    "#     - chunk_size: the total amount of enteries read in every year for the EOF PIM calculation\n",
    "def Chunk_size_EOF_calc(GB_avail):\n",
    "    # calculating the total GB\n",
    "    anom = read_anom_compressed(1994)\n",
    "    chunk_size = int((GB_avail*1e9 - anom.nbytes)/4 * 1/(len(years)))\n",
    "    print(f\"You can read in {chunk_size} enteries every year.\")  \n",
    "    return chunk_size\n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function computes EOFs in parts.\n",
    "# To save on RAM we exclude points with NaN when reading\n",
    "# Input:\n",
    "#         - years: 1D int array with all years to read in of the anomalies.\n",
    "#                  Length of this will also be the max amount of modes\n",
    "# Output:\n",
    "#         - None: function saves all EOF modes in sperate files\n",
    "# Important Variables:\n",
    "#         - total_modes: int of the total amount of modes to compute. The default is the max (see input for max)\n",
    "#         - num_ind: 2D array that tells us which indexes have ocean data(excludes land/NaN).\n",
    "#         - chunk_size: the total amount of grid points to read in each year. Remember we are excluding NaN so\n",
    "#                       this is total grid points with data that we are reading in\n",
    "#         - read: a subset of num_ind that contains a total of chunk_size indexes for that iteration.\n",
    "#                 This variable makes sure we are not reading the same chunk, and the for loop it is in makes\n",
    "#                 sure we read to the end even if the last chunk is less than chunk_size\n",
    "#         - anom_mat: 2D space time anomaly matrix without NaN. This is at most dim(chunk_size, Y)\n",
    "#         - EOF_mat: 3D Array of size (depth, lat, lon). This contains the resulting EOFs from the\n",
    "#                    multiplication.\n",
    "#                   NOTE: this matrix does contain NaNs. We make sure that the resulting multiplacation goes\n",
    "#                         to the correct index bny uising the variable read for the indexing.\n",
    "def compute_EOFs(years, chunk_size):\n",
    "# Compute EOFs over all depths at once by chunking through the list of (depth, lat, lon) locations where anom_base is not NaN.\n",
    "    start = time.time()                            # for timing\n",
    "    total_modes = len(years)+1                     # number of EOF modes to compute\n",
    "\n",
    "    # read one year just to know the shape and mask\n",
    "    anom_base = read_anom_raw(1994)                # shape (depth, lat, lon)\n",
    "\n",
    "    # get all non-NaN grid-points (depth, lat, lon)\n",
    "    num_ind = np.argwhere(~np.isnan(anom_base))    # shape (N, 3)\n",
    "\n",
    "    for j in range(0, num_ind.shape[0], chunk_size):\n",
    "        read = num_ind[j:j+chunk_size]             # shape (M, 3)\n",
    "        anom_mat = np.zeros((read.shape[0], len(years)), dtype=np.float32)\n",
    "        for k, y in enumerate(years):\n",
    "            # read the full 3D anomalies for year y\n",
    "            anom_mat[:, k] = read_anom_parts(y, read)  # (depth, lat, lon)\n",
    "\n",
    "        # for each EOF mode, write the computed values\n",
    "        for mode in range(1, total_modes):\n",
    "            fn = 'EOF_'+str(mode)+'.nc'\n",
    "            fn = os.path.join(EOF_directory, fn)\n",
    "            EOF_ncfile = ds(fn, 'a')\n",
    "            EOF = EOF_ncfile.variables['EOF']\n",
    "            EOF_mat = EOF[:].filled()\n",
    "            # compute EOFs and write to specified lat, lon\n",
    "            EOF_mat[read[:,0], read[:,1], read[:,2]] = anom_mat @ eigvecs[:, mode-1]\n",
    "            EOF[:] = EOF_mat\n",
    "            EOF_ncfile.close()\n",
    "\n",
    "    # normalize_EOFs(len(years))\n",
    "    end = time.time()\n",
    "    time_total = end - start\n",
    "    print(time_total)\n",
    "    return \n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "# Function normalizes the EOFs by dividing by magnitude\n",
    "#\n",
    "# Input:\n",
    "#         - tot_modes: an int describing total amount of modes\n",
    "# Output:\n",
    "#         - None: saves the EOFs to the EOF files\n",
    "# Important Variables:\n",
    "def normalize_EOFs(tot_modes):\n",
    "    for mode in range(1,tot_modes+1):\n",
    "        fn      = 'EOF_'+str(mode)+'.nc'\n",
    "        fn      = os.path.join(EOF_directory, fn)     # join with EOF path\n",
    "        EOF_ncfile = ds(fn, 'a')\n",
    "        EOF     = EOF_ncfile.variables['EOF']\n",
    "        EOF_mag = EOF[:].compressed()                      # flattens and gets rid of NaN\n",
    "        EOF[:]  = EOF[:].filled()/np.linalg.norm(EOF_mag)  # divide by magnitude\n",
    "        EOF_ncfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64c82094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'E:/GLORYS/cut_EOFs/Entire Ocean PIM' already exists.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_1.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_2.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_3.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_4.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_5.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_6.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_7.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_8.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_9.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_10.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_11.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_12.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_13.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_14.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_15.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_16.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_17.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_18.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_19.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_20.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_21.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_22.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_23.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_24.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_25.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_26.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_27.nc' exists. Moving to next iteration.\n",
      "File 'E:/GLORYS/cut_EOFs/Entire Ocean PIM\\EOF_28.nc' exists. Moving to next iteration.\n",
      "Total of '28' EOF files created\n"
     ]
    }
   ],
   "source": [
    "create_EOF_files(len(years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c61b6-1aeb-49f3-a69a-a32fb8af78e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input how much GB you wish to use\n",
    "GB_avail = int(input(\"How Many GB would you like to use?:\"))\n",
    "chunk_size = Chunk_size_EOF_calc(GB_avail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c1673daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11725.266805887222\n"
     ]
    }
   ],
   "source": [
    "compute_EOFs(years, chunk_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
